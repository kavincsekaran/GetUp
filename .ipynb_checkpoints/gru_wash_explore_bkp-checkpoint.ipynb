{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/home/kchandrasekaran/virtualenvs/pytorch/bin/python\n",
    "#SBATCH --job-name=Tune_BiGRU_inverse_GridSearch\n",
    "#SBATCH --output=Tune_BiGRU_inverse_GridSearch.log\n",
    "#SBATCH --mem=32G\n",
    "#SBATCH -n 8\n",
    "#SBATCH --time=240:00:00\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH -C V100\n",
    "#SBATCH -p emmanuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "import itertools\n",
    "from collections import deque\n",
    "from collections import Counter\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import sklearn.metrics as met\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_titles_clean = ['Walking',\n",
    "                      'Lying Down',\n",
    "                      'Standing',\n",
    "                      'Phone in Bag',\n",
    "                      'Phone in Hand',\n",
    "                      'Phone in Pocket',\n",
    "                      'Phone on Table',\n",
    "                      'Sitting',\n",
    "                      'Sleeping',\n",
    "                      'Talking',\n",
    "                      'Toilet']\n",
    "\n",
    "sensor_titles_clean = ['Accelerometer',\n",
    "                       'Gyroscope',\n",
    "                       'Magnetometer',\n",
    "                       'Location Services',\n",
    "                       'Audio',\n",
    "                       'Discrete',\n",
    "                       'Other']\n",
    "\n",
    "watch_features = ['watch_acceleration:magnitude_stats:mean',\n",
    "                  'watch_acceleration:magnitude_stats:std',\n",
    "                  'watch_acceleration:magnitude_stats:moment3',\n",
    "                  'watch_acceleration:magnitude_stats:moment4',\n",
    "                  'watch_acceleration:magnitude_stats:percentile25',\n",
    "                  'watch_acceleration:magnitude_stats:percentile50',\n",
    "                  'watch_acceleration:magnitude_stats:percentile75',\n",
    "                  'watch_acceleration:magnitude_stats:value_entropy',\n",
    "                  'watch_acceleration:magnitude_stats:time_entropy',\n",
    "                  'watch_acceleration:magnitude_spectrum:log_energy_band0',\n",
    "                  'watch_acceleration:magnitude_spectrum:log_energy_band1',\n",
    "                  'watch_acceleration:magnitude_spectrum:log_energy_band2',\n",
    "                  'watch_acceleration:magnitude_spectrum:log_energy_band3',\n",
    "                  'watch_acceleration:magnitude_spectrum:log_energy_band4',\n",
    "                  'watch_acceleration:magnitude_spectrum:spectral_entropy',\n",
    "                  'watch_acceleration:magnitude_autocorrelation:period',\n",
    "                  'watch_acceleration:magnitude_autocorrelation:normalized_ac',\n",
    "                  'watch_acceleration:3d:mean_x',\n",
    "                  'watch_acceleration:3d:mean_y',\n",
    "                  'watch_acceleration:3d:mean_z',\n",
    "                  'watch_acceleration:3d:std_x',\n",
    "                  'watch_acceleration:3d:std_y',\n",
    "                  'watch_acceleration:3d:std_z',\n",
    "                  'watch_acceleration:3d:ro_xy',\n",
    "                  'watch_acceleration:3d:ro_xz',\n",
    "                  'watch_acceleration:3d:ro_yz',\n",
    "                  'watch_acceleration:spectrum:x_log_energy_band0',\n",
    "                  'watch_acceleration:spectrum:x_log_energy_band1',\n",
    "                  'watch_acceleration:spectrum:x_log_energy_band2',\n",
    "                  'watch_acceleration:spectrum:x_log_energy_band3',\n",
    "                  'watch_acceleration:spectrum:x_log_energy_band4',\n",
    "                  'watch_acceleration:spectrum:y_log_energy_band0',\n",
    "                  'watch_acceleration:spectrum:y_log_energy_band1',\n",
    "                  'watch_acceleration:spectrum:y_log_energy_band2',\n",
    "                  'watch_acceleration:spectrum:y_log_energy_band3',\n",
    "                  'watch_acceleration:spectrum:y_log_energy_band4',\n",
    "                  'watch_acceleration:spectrum:z_log_energy_band0',\n",
    "                  'watch_acceleration:spectrum:z_log_energy_band1',\n",
    "                  'watch_acceleration:spectrum:z_log_energy_band2',\n",
    "                  'watch_acceleration:spectrum:z_log_energy_band3',\n",
    "                  'watch_acceleration:spectrum:z_log_energy_band4',\n",
    "                  'watch_acceleration:relative_directions:avr_cosine_similarity_lag_range0',\n",
    "                  'watch_acceleration:relative_directions:avr_cosine_similarity_lag_range1',\n",
    "                  'watch_acceleration:relative_directions:avr_cosine_similarity_lag_range2',\n",
    "                  'watch_acceleration:relative_directions:avr_cosine_similarity_lag_range3',\n",
    "                  'watch_acceleration:relative_directions:avr_cosine_similarity_lag_range4',\n",
    "                  'watch_heading:mean_cos',\n",
    "                  'watch_heading:std_cos',\n",
    "                  'watch_heading:mom3_cos',\n",
    "                  'watch_heading:mom4_cos',\n",
    "                  'watch_heading:mean_sin',\n",
    "                  'watch_heading:std_sin',\n",
    "                  'watch_heading:mom3_sin',\n",
    "                  'watch_heading:mom4_sin',\n",
    "                  'watch_heading:entropy_8bins']\n",
    "\n",
    "contexts_other = ['label:LAB_WORK',\n",
    "                  'label:IN_CLASS',\n",
    "                  'label:IN_A_MEETING',\n",
    "                  'label:LOC_main_workplace',\n",
    "                  'label:ON_A_BUS',\n",
    "                  'label:DRIVE_-_I_M_THE_DRIVER',\n",
    "                  'label:DRIVE_-_I_M_A_PASSENGER',\n",
    "                  'label:LOC_home',\n",
    "                  'label:FIX_restaurant',\n",
    "                  'label:COOKING',\n",
    "                  'label:SHOPPING',\n",
    "                  'label:STROLLING',\n",
    "                  'label:DRINKING__ALCOHOL_',\n",
    "                  'label:BATHING_-_SHOWER',\n",
    "                  'label:CLEANING',\n",
    "                  'label:DOING_LAUNDRY',\n",
    "                  'label:WASHING_DISHES',\n",
    "                  'label:WATCHING_TV',\n",
    "                  'label:AT_A_PARTY',\n",
    "                  'label:AT_A_BAR',\n",
    "                  'label:LOC_beach',\n",
    "                  'label:COMPUTER_WORK',\n",
    "                  'label:EATING',\n",
    "                  'label:DRESSING',\n",
    "                  'label:AT_THE_GYM',\n",
    "                  'label:AT_SCHOOL',\n",
    "                  'label:WITH_CO-WORKERS',\n",
    "                  'label:WITH_FRIENDS',\n",
    "                  'label_source']\n",
    "\n",
    "contexts_activity = ['label:LYING_DOWN',\n",
    "                     'label:SITTING',\n",
    "                     'label:FIX_walking',\n",
    "                     'label:FIX_running',\n",
    "                     'label:BICYCLING',\n",
    "                     'label:SLEEPING',\n",
    "                     'label:IN_A_CAR',\n",
    "                     'label:OR_exercise',\n",
    "                     'label:SURFING_THE_INTERNET',\n",
    "                     'label:TALKING',\n",
    "                     'label:EATING',\n",
    "                     'label:TOILET',\n",
    "                     'label:GROOMING',\n",
    "                     'label:STAIRS_-_GOING_UP',\n",
    "                     'label:STAIRS_-_GOING_DOWN',\n",
    "                     'label:ELEVATOR',\n",
    "                     'label:OR_standing']\n",
    "\n",
    "contexts_in_out = ['label:OR_indoors',\n",
    "                   'label:OR_outside']\n",
    "\n",
    "contexts_prioception = ['label:PHONE_IN_POCKET',\n",
    "                        'label:PHONE_IN_HAND',\n",
    "                        'label:PHONE_IN_BAG',\n",
    "                        'label:PHONE_ON_TABLE']\n",
    "\n",
    "contexts_immediate = ['label:LYING_DOWN',\n",
    "                      'label:SITTING',\n",
    "                      'label:FIX_walking',\n",
    "                      'label:SLEEPING',\n",
    "                      'label:OR_standing',\n",
    "                      'label:PHONE_IN_POCKET',\n",
    "                      'label:PHONE_IN_HAND',\n",
    "                      'label:PHONE_IN_BAG',\n",
    "                      'label:PHONE_ON_TABLE',\n",
    "                      'label:TOILET',\n",
    "                      'label:TALKING']\n",
    "\n",
    "label_information = ['timestamp',\n",
    "                     'label_source']\n",
    "\n",
    "accelerometer = ['raw_acc:magnitude_stats:mean',\n",
    "                 'raw_acc:magnitude_stats:std',\n",
    "                 'raw_acc:magnitude_stats:moment3',\n",
    "                 'raw_acc:magnitude_stats:moment4',\n",
    "                 'raw_acc:magnitude_stats:percentile25',\n",
    "                 'raw_acc:magnitude_stats:percentile50',\n",
    "                 'raw_acc:magnitude_stats:percentile75',\n",
    "                 'raw_acc:magnitude_stats:value_entropy',\n",
    "                 'raw_acc:magnitude_stats:time_entropy',\n",
    "                 'raw_acc:magnitude_spectrum:log_energy_band0',\n",
    "                 'raw_acc:magnitude_spectrum:log_energy_band1',\n",
    "                 'raw_acc:magnitude_spectrum:log_energy_band2',\n",
    "                 'raw_acc:magnitude_spectrum:log_energy_band3',\n",
    "                 'raw_acc:magnitude_spectrum:log_energy_band4',\n",
    "                 'raw_acc:magnitude_spectrum:spectral_entropy',\n",
    "                 'raw_acc:magnitude_autocorrelation:period',\n",
    "                 'raw_acc:magnitude_autocorrelation:normalized_ac',\n",
    "                 'raw_acc:3d:mean_x',\n",
    "                 'raw_acc:3d:mean_y',\n",
    "                 'raw_acc:3d:mean_z',\n",
    "                 'raw_acc:3d:std_x',\n",
    "                 'raw_acc:3d:std_y',\n",
    "                 'raw_acc:3d:std_z',\n",
    "                 'raw_acc:3d:ro_xy',\n",
    "                 'raw_acc:3d:ro_xz',\n",
    "                 'raw_acc:3d:ro_yz']\n",
    "\n",
    "gyroscope = ['proc_gyro:magnitude_stats:mean',\n",
    "             'proc_gyro:magnitude_stats:std',\n",
    "             'proc_gyro:magnitude_stats:moment3',\n",
    "             'proc_gyro:magnitude_stats:moment4',\n",
    "             'proc_gyro:magnitude_stats:percentile25',\n",
    "             'proc_gyro:magnitude_stats:percentile50',\n",
    "             'proc_gyro:magnitude_stats:percentile75',\n",
    "             'proc_gyro:magnitude_stats:value_entropy',\n",
    "             'proc_gyro:magnitude_stats:time_entropy',\n",
    "             'proc_gyro:magnitude_spectrum:log_energy_band0',\n",
    "             'proc_gyro:magnitude_spectrum:log_energy_band1',\n",
    "             'proc_gyro:magnitude_spectrum:log_energy_band2',\n",
    "             'proc_gyro:magnitude_spectrum:log_energy_band3',\n",
    "             'proc_gyro:magnitude_spectrum:log_energy_band4',\n",
    "             'proc_gyro:magnitude_spectrum:spectral_entropy',\n",
    "             'proc_gyro:magnitude_autocorrelation:period',\n",
    "             'proc_gyro:magnitude_autocorrelation:normalized_ac',\n",
    "             'proc_gyro:3d:mean_x',\n",
    "             'proc_gyro:3d:mean_y',\n",
    "             'proc_gyro:3d:mean_z',\n",
    "             'proc_gyro:3d:std_x',\n",
    "             'proc_gyro:3d:std_y',\n",
    "             'proc_gyro:3d:std_z',\n",
    "             'proc_gyro:3d:ro_xy',\n",
    "             'proc_gyro:3d:ro_xz',\n",
    "             'proc_gyro:3d:ro_yz']\n",
    "\n",
    "magnetometer = ['raw_magnet:magnitude_stats:mean',\n",
    "                'raw_magnet:magnitude_stats:std',\n",
    "                'raw_magnet:magnitude_stats:moment3',\n",
    "                'raw_magnet:magnitude_stats:moment4',\n",
    "                'raw_magnet:magnitude_stats:percentile25',\n",
    "                'raw_magnet:magnitude_stats:percentile50',\n",
    "                'raw_magnet:magnitude_stats:percentile75',\n",
    "                'raw_magnet:magnitude_stats:value_entropy',\n",
    "                'raw_magnet:magnitude_stats:time_entropy',\n",
    "                'raw_magnet:magnitude_spectrum:log_energy_band0',\n",
    "                'raw_magnet:magnitude_spectrum:log_energy_band1',\n",
    "                'raw_magnet:magnitude_spectrum:log_energy_band2',\n",
    "                'raw_magnet:magnitude_spectrum:log_energy_band3',\n",
    "                'raw_magnet:magnitude_spectrum:log_energy_band4',\n",
    "                'raw_magnet:magnitude_spectrum:spectral_entropy',\n",
    "                'raw_magnet:magnitude_autocorrelation:period',\n",
    "                'raw_magnet:magnitude_autocorrelation:normalized_ac',\n",
    "                'raw_magnet:3d:mean_x',\n",
    "                'raw_magnet:3d:mean_y',\n",
    "                'raw_magnet:3d:mean_z',\n",
    "                'raw_magnet:3d:std_x',\n",
    "                'raw_magnet:3d:std_y',\n",
    "                'raw_magnet:3d:std_z',\n",
    "                'raw_magnet:3d:ro_xy',\n",
    "                'raw_magnet:3d:ro_xz',\n",
    "                'raw_magnet:3d:ro_yz',\n",
    "                'raw_magnet:avr_cosine_similarity_lag_range0',\n",
    "                'raw_magnet:avr_cosine_similarity_lag_range1',\n",
    "                'raw_magnet:avr_cosine_similarity_lag_range2',\n",
    "                'raw_magnet:avr_cosine_similarity_lag_range3',\n",
    "                'raw_magnet:avr_cosine_similarity_lag_range4']\n",
    "\n",
    "location = ['location:num_valid_updates',\n",
    "            'location:log_latitude_range',\n",
    "            'location:log_longitude_range',\n",
    "            'location:min_altitude',\n",
    "            'location:max_altitude',\n",
    "            'location:min_speed',\n",
    "            'location:max_speed',\n",
    "            'location:best_horizontal_accuracy',\n",
    "            'location:best_vertical_accuracy',\n",
    "            'location:diameter',\n",
    "            'location:log_diameter',\n",
    "            'location_quick_features:std_lat',\n",
    "            'location_quick_features:std_long',\n",
    "            'location_quick_features:lat_change',\n",
    "            'location_quick_features:long_change',\n",
    "            'location_quick_features:mean_abs_lat_deriv',\n",
    "            'location_quick_features:mean_abs_long_deriv']\n",
    "\n",
    "audio = ['audio_naive:mfcc0:mean',\n",
    "         'audio_naive:mfcc1:mean',\n",
    "         'audio_naive:mfcc2:mean',\n",
    "         'audio_naive:mfcc3:mean',\n",
    "         'audio_naive:mfcc4:mean',\n",
    "         'audio_naive:mfcc5:mean',\n",
    "         'audio_naive:mfcc6:mean',\n",
    "         'audio_naive:mfcc7:mean',\n",
    "         'audio_naive:mfcc8:mean',\n",
    "         'audio_naive:mfcc9:mean',\n",
    "         'audio_naive:mfcc10:mean',\n",
    "         'audio_naive:mfcc11:mean',\n",
    "         'audio_naive:mfcc12:mean',\n",
    "         'audio_naive:mfcc0:std',\n",
    "         'audio_naive:mfcc1:std',\n",
    "         'audio_naive:mfcc2:std',\n",
    "         'audio_naive:mfcc3:std',\n",
    "         'audio_naive:mfcc4:std',\n",
    "         'audio_naive:mfcc5:std',\n",
    "         'audio_naive:mfcc6:std',\n",
    "         'audio_naive:mfcc7:std',\n",
    "         'audio_naive:mfcc8:std',\n",
    "         'audio_naive:mfcc9:std',\n",
    "         'audio_naive:mfcc10:std',\n",
    "         'audio_naive:mfcc11:std',\n",
    "         'audio_naive:mfcc12:std',\n",
    "         'audio_properties:max_abs_value',\n",
    "         'audio_properties:normalization_multiplier']\n",
    "\n",
    "discrete = ['discrete:app_state:is_active',\n",
    "            'discrete:app_state:is_inactive',\n",
    "            'discrete:app_state:is_background',\n",
    "            'discrete:app_state:missing',\n",
    "            'discrete:battery_plugged:is_ac',\n",
    "            'discrete:battery_plugged:is_usb',\n",
    "            'discrete:battery_plugged:is_wireless',\n",
    "            'discrete:battery_plugged:missing',\n",
    "            'discrete:battery_state:is_unknown',\n",
    "            'discrete:battery_state:is_unplugged',\n",
    "            'discrete:battery_state:is_not_charging',\n",
    "            'discrete:battery_state:is_discharging',\n",
    "            'discrete:battery_state:is_charging',\n",
    "            'discrete:battery_state:is_full',\n",
    "            'discrete:battery_state:missing',\n",
    "            'discrete:on_the_phone:is_False',\n",
    "            'discrete:on_the_phone:is_True',\n",
    "            'discrete:on_the_phone:missing',\n",
    "            'discrete:ringer_mode:is_normal',\n",
    "            'discrete:ringer_mode:is_silent_no_vibrate',\n",
    "            'discrete:ringer_mode:is_silent_with_vibrate',\n",
    "            'discrete:ringer_mode:missing',\n",
    "            'discrete:wifi_status:is_not_reachable',\n",
    "            'discrete:wifi_status:is_reachable_via_wifi',\n",
    "            'discrete:wifi_status:is_reachable_via_wwan',\n",
    "            'discrete:wifi_status:missing',\n",
    "            'lf_measurements:light',\n",
    "            'lf_measurements:pressure',\n",
    "            'lf_measurements:proximity_cm',\n",
    "            'lf_measurements:proximity',\n",
    "            'lf_measurements:relative_humidity',\n",
    "            'lf_measurements:battery_level',\n",
    "            'lf_measurements:screen_brightness',\n",
    "            'lf_measurements:temperature_ambient',\n",
    "            'discrete:time_of_day:between0and6',\n",
    "            'discrete:time_of_day:between3and9',\n",
    "            'discrete:time_of_day:between6and12',\n",
    "            'discrete:time_of_day:between9and15',\n",
    "            'discrete:time_of_day:between12and18',\n",
    "            'discrete:time_of_day:between15and21',\n",
    "            'discrete:time_of_day:between18and24',\n",
    "            'discrete:time_of_day:between21and3']\n",
    "\n",
    "proc_magnet = ['proc_magnet:magnitude_spectrum:log_energy_band1',\n",
    "                 'proc_magnet:3d:mean_x',\n",
    "                 'proc_magnet:magnitude_spectrum:log_energy_band3',\n",
    "                 'proc_magnet:3d:ro_yz',\n",
    "                 'proc_magnet:magnitude_stats:percentile75',\n",
    "                 'proc_magnet:magnitude_stats:value_entropy',\n",
    "                 'proc_magnet:avr_cosine_similarity_lag_range0',\n",
    "                 'proc_magnet:magnitude_autocorrelation:period',\n",
    "                 'proc_magnet:3d:std_x',\n",
    "                 'proc_magnet:magnitude_stats:moment3',\n",
    "                 'proc_magnet:magnitude_stats:percentile25',\n",
    "                 'proc_magnet:magnitude_spectrum:spectral_entropy',\n",
    "                 'proc_magnet:magnitude_stats:std',\n",
    "                 'proc_magnet:magnitude_stats:percentile50',\n",
    "                 'proc_magnet:3d:ro_xy',\n",
    "                 'proc_magnet:magnitude_stats:moment4',\n",
    "                 'proc_magnet:avr_cosine_similarity_lag_range1',\n",
    "                 'proc_magnet:avr_cosine_similarity_lag_range3',\n",
    "                 'proc_magnet:magnitude_spectrum:log_energy_band4',\n",
    "                 'proc_magnet:magnitude_spectrum:log_energy_band0',\n",
    "                 'proc_magnet:3d:std_z',\n",
    "                 'proc_magnet:magnitude_spectrum:log_energy_band2',\n",
    "                 'proc_magnet:3d:mean_z',\n",
    "                 'proc_magnet:3d:mean_y',\n",
    "                 'proc_magnet:magnitude_autocorrelation:normalized_ac',\n",
    "                 'proc_magnet:magnitude_stats:mean',\n",
    "                 'proc_magnet:avr_cosine_similarity_lag_range4',\n",
    "                 'proc_magnet:avr_cosine_similarity_lag_range2',\n",
    "                 'proc_magnet:magnitude_stats:time_entropy',\n",
    "                 'proc_magnet:3d:ro_xz',\n",
    "                 'proc_magnet:3d:std_y'\n",
    "                 ]\n",
    "\n",
    "audio_rest = ['audio_naive:mfcc10:std',\n",
    "                 'mfcc_7',\n",
    "                 'audio_naive:mfcc1:std',\n",
    "                 'audio_naive:mfcc3:mean',\n",
    "                 'mfcc_8',\n",
    "                 'audio_naive:mfcc6:mean',\n",
    "                 'audio_naive:mfcc7:mean',\n",
    "                 'mfcc_25',\n",
    "                 'mfcc_23',\n",
    "                 'mfcc_9',\n",
    "                 'audio_naive:mfcc5:mean',\n",
    "                 'mfcc_14',\n",
    "                 'audio_naive:mfcc3:std',\n",
    "                 'audio_naive:mfcc10:mean',\n",
    "                 'mfcc_20',\n",
    "                 'mfcc_15',\n",
    "                 'audio_naive:mfcc9:std',\n",
    "                 'audio_naive:mfcc7:std',\n",
    "                 'audio_naive:mfcc6:std',\n",
    "                 'mfcc_0',\n",
    "                 'audio_naive:mfcc2:std',\n",
    "                 'audio_naive:mfcc11:std',\n",
    "                 'audio_naive:mfcc4:std',\n",
    "                 'audio_naive:mfcc9:mean',\n",
    "                 'audio_naive:mfcc2:mean',\n",
    "                 'mfcc_5',\n",
    "                 'mfcc_17',\n",
    "                 'audio_naive:mfcc0:mean',\n",
    "                 'mfcc_21',\n",
    "                 'mfcc_1',\n",
    "                 'audio_naive:mfcc5:std',\n",
    "                 'mfcc_18',\n",
    "                 'mfcc_4',\n",
    "                 'audio_naive:mfcc4:mean',\n",
    "                 'mfcc_13',\n",
    "                 'audio_naive:mfcc1:mean',\n",
    "                 'mfcc_22',\n",
    "                 'mfcc_24',\n",
    "                 'mfcc_12',\n",
    "                 'audio_naive:mfcc0:std',\n",
    "                 'mfcc_6',\n",
    "                 'audio_naive:mfcc12:std',\n",
    "                 'audio_naive:mfcc8:mean',\n",
    "                 'audio_naive:mfcc12:mean',\n",
    "                 'audio_naive:mfcc8:std',\n",
    "                 'mfcc_2',\n",
    "                 'audio_properties:max_abs_value',\n",
    "                 'mfcc_19',\n",
    "                 'mfcc_10',\n",
    "                 'mfcc_3',\n",
    "                 'mfcc_16',\n",
    "                 'audio_naive:mfcc11:mean',\n",
    "                 'mfcc_11',\n",
    "                 'audio_properties:normalization_multiplier'\n",
    "             ]\n",
    "\n",
    "labels = ['Laying Down (action)',\n",
    "          'Sneezing',\n",
    "          'Talking On Phone',\n",
    "          'Typing',\n",
    "          'Phone in Pocket',\n",
    "          'Standing up (action)',\n",
    "          'Stairs - Going Up',\n",
    "          'Jogging',\n",
    "          'Running',\n",
    "          'Assigned Prioception',\n",
    "          'Sitting',\n",
    "          'Sleeping',\n",
    "          'Jumping',\n",
    "          'Coughing',\n",
    "          'Phone in Table, Facing Down',\n",
    "          'Phone in Table, Facing Up',\n",
    "          'Stairs - Going Down',\n",
    "          'Phone in Hand',\n",
    "          'Sitting Up (action)',\n",
    "          'Phone in Bag',\n",
    "          'Bathroom',\n",
    "          'Walking',\n",
    "          'Trembling',\n",
    "          'Lying Down',\n",
    "          'Standing',\n",
    "          'Sitting Down (action)',\n",
    "          'Assigned Prioception - Except Phone in Hand'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/kchandrasekaran/wash/Datasets/WASH_User_Study/study_folds.pickle\", 'rb') as handle:\n",
    "    folds_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/kchandrasekaran/wash/Datasets/WASH_User_Study/Data_with_CONTEXTS/\"\n",
    "filename = \"with_audio_UUID_0077_merged_labels_with_contexts.csv\"\n",
    "context_data = pd.read_csv(data_path + filename, header=0, index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>raw_acc:magnitude_stats:mean</th>\n",
       "      <th>raw_acc:magnitude_stats:std</th>\n",
       "      <th>raw_acc:magnitude_stats:moment3</th>\n",
       "      <th>raw_acc:magnitude_stats:moment4</th>\n",
       "      <th>raw_acc:magnitude_stats:percentile25</th>\n",
       "      <th>raw_acc:magnitude_stats:percentile50</th>\n",
       "      <th>raw_acc:magnitude_stats:percentile75</th>\n",
       "      <th>raw_acc:magnitude_stats:value_entropy</th>\n",
       "      <th>raw_acc:magnitude_stats:time_entropy</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_22</th>\n",
       "      <th>mfcc_23</th>\n",
       "      <th>mfcc_24</th>\n",
       "      <th>mfcc_25</th>\n",
       "      <th>Walking, Phone in Pocket</th>\n",
       "      <th>Walking, Phone in Hand</th>\n",
       "      <th>Walking, Phone in Bag</th>\n",
       "      <th>Toilet, Phone in Pocket</th>\n",
       "      <th>Exercising, Phone in Pocket</th>\n",
       "      <th>Laying Down, Phone on Table</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1544893135</td>\n",
       "      <td>1.030530</td>\n",
       "      <td>0.122373</td>\n",
       "      <td>0.179672</td>\n",
       "      <td>0.241713</td>\n",
       "      <td>0.991075</td>\n",
       "      <td>1.010665</td>\n",
       "      <td>1.041206</td>\n",
       "      <td>1.820870</td>\n",
       "      <td>4.781131</td>\n",
       "      <td>...</td>\n",
       "      <td>4.416164</td>\n",
       "      <td>4.251079</td>\n",
       "      <td>6.968697</td>\n",
       "      <td>5.147111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1544893136</td>\n",
       "      <td>1.005785</td>\n",
       "      <td>0.037443</td>\n",
       "      <td>0.028159</td>\n",
       "      <td>0.058322</td>\n",
       "      <td>0.987816</td>\n",
       "      <td>1.002092</td>\n",
       "      <td>1.019371</td>\n",
       "      <td>2.219222</td>\n",
       "      <td>3.931135</td>\n",
       "      <td>...</td>\n",
       "      <td>14.177430</td>\n",
       "      <td>21.678520</td>\n",
       "      <td>30.050220</td>\n",
       "      <td>52.379090</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1544893137</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.086812</td>\n",
       "      <td>0.082233</td>\n",
       "      <td>0.119346</td>\n",
       "      <td>0.936999</td>\n",
       "      <td>0.992348</td>\n",
       "      <td>1.019545</td>\n",
       "      <td>2.476304</td>\n",
       "      <td>3.928134</td>\n",
       "      <td>...</td>\n",
       "      <td>12.640050</td>\n",
       "      <td>15.262320</td>\n",
       "      <td>15.529420</td>\n",
       "      <td>14.284940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1544893138</td>\n",
       "      <td>1.008235</td>\n",
       "      <td>0.053096</td>\n",
       "      <td>0.029339</td>\n",
       "      <td>0.073357</td>\n",
       "      <td>0.984623</td>\n",
       "      <td>1.004693</td>\n",
       "      <td>1.039554</td>\n",
       "      <td>2.466066</td>\n",
       "      <td>3.910638</td>\n",
       "      <td>...</td>\n",
       "      <td>1.503617</td>\n",
       "      <td>1.870117</td>\n",
       "      <td>1.973305</td>\n",
       "      <td>1.935158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1544893139</td>\n",
       "      <td>0.981533</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>-0.185252</td>\n",
       "      <td>0.301615</td>\n",
       "      <td>0.893205</td>\n",
       "      <td>1.018514</td>\n",
       "      <td>1.079224</td>\n",
       "      <td>2.298272</td>\n",
       "      <td>3.907010</td>\n",
       "      <td>...</td>\n",
       "      <td>7.764890</td>\n",
       "      <td>6.784469</td>\n",
       "      <td>5.615699</td>\n",
       "      <td>3.798430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 233 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp  raw_acc:magnitude_stats:mean  raw_acc:magnitude_stats:std  \\\n",
       "0  1544893135                      1.030530                     0.122373   \n",
       "1  1544893136                      1.005785                     0.037443   \n",
       "2  1544893137                      0.999908                     0.086812   \n",
       "3  1544893138                      1.008235                     0.053096   \n",
       "4  1544893139                      0.981533                     0.209302   \n",
       "\n",
       "   raw_acc:magnitude_stats:moment3  raw_acc:magnitude_stats:moment4  \\\n",
       "0                         0.179672                         0.241713   \n",
       "1                         0.028159                         0.058322   \n",
       "2                         0.082233                         0.119346   \n",
       "3                         0.029339                         0.073357   \n",
       "4                        -0.185252                         0.301615   \n",
       "\n",
       "   raw_acc:magnitude_stats:percentile25  raw_acc:magnitude_stats:percentile50  \\\n",
       "0                              0.991075                              1.010665   \n",
       "1                              0.987816                              1.002092   \n",
       "2                              0.936999                              0.992348   \n",
       "3                              0.984623                              1.004693   \n",
       "4                              0.893205                              1.018514   \n",
       "\n",
       "   raw_acc:magnitude_stats:percentile75  \\\n",
       "0                              1.041206   \n",
       "1                              1.019371   \n",
       "2                              1.019545   \n",
       "3                              1.039554   \n",
       "4                              1.079224   \n",
       "\n",
       "   raw_acc:magnitude_stats:value_entropy  \\\n",
       "0                               1.820870   \n",
       "1                               2.219222   \n",
       "2                               2.476304   \n",
       "3                               2.466066   \n",
       "4                               2.298272   \n",
       "\n",
       "   raw_acc:magnitude_stats:time_entropy             ...               \\\n",
       "0                              4.781131             ...                \n",
       "1                              3.931135             ...                \n",
       "2                              3.928134             ...                \n",
       "3                              3.910638             ...                \n",
       "4                              3.907010             ...                \n",
       "\n",
       "     mfcc_22    mfcc_23    mfcc_24    mfcc_25  Walking, Phone in Pocket  \\\n",
       "0   4.416164   4.251079   6.968697   5.147111                         0   \n",
       "1  14.177430  21.678520  30.050220  52.379090                         0   \n",
       "2  12.640050  15.262320  15.529420  14.284940                         0   \n",
       "3   1.503617   1.870117   1.973305   1.935158                         0   \n",
       "4   7.764890   6.784469   5.615699   3.798430                         0   \n",
       "\n",
       "   Walking, Phone in Hand  Walking, Phone in Bag  Toilet, Phone in Pocket  \\\n",
       "0                       0                      0                        0   \n",
       "1                       0                      0                        0   \n",
       "2                       0                      0                        0   \n",
       "3                       0                      0                        0   \n",
       "4                       0                      0                        0   \n",
       "\n",
       "   Exercising, Phone in Pocket  Laying Down, Phone on Table  \n",
       "0                            0                            0  \n",
       "1                            0                            0  \n",
       "2                            0                            0  \n",
       "3                            0                            0  \n",
       "4                            0                            0  \n",
       "\n",
       "[5 rows x 233 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/kchandrasekaran/wash/Datasets/WASH_User_Study/32_97_with_audio/\"\n",
    "train_files = []\n",
    "test_files = []\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for i in range(5):\n",
    "    train_test_split = folds_dict[i]\n",
    "    #print(train_test_split)\n",
    "    train_files += train_test_split[0]\n",
    "    test_files += train_test_split[1]\n",
    "    \n",
    "    for filename in train_files:\n",
    "        #print(filename)\n",
    "        user = pd.read_csv(data_path + filename + '.csv', header=0, index_col= 0)\n",
    "        train_data = train_data.append(user)\n",
    "    \n",
    "    for filename in test_files:\n",
    "        user = pd.read_csv(data_path + filename + '.csv', header=0, index_col= 0)\n",
    "        test_data = test_data.append(user)\n",
    "\n",
    "    X_train = train_data[list(set(train_data.columns)^set(labels))]\n",
    "    Y_train = train_data[labels]\n",
    "\n",
    "    X_test = test_data[list(set(test_data.columns)^set(labels))]\n",
    "    Y_test = test_data[labels]\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_label_names = [\n",
    "          'Stairs - Going Up',\n",
    "          'Jogging',\n",
    "          'Running',\n",
    "          'Sitting',\n",
    "          'Sleeping',\n",
    "          'Jumping',\n",
    "          'Stairs - Going Down',\n",
    "          'Walking',\n",
    "          'Trembling',\n",
    "          'Lying Down',\n",
    "          'Standing'\n",
    "         ]\n",
    "transition_label_names = [\n",
    "        'Laying Down (action)',\n",
    "        'Sitting Down (action)',\n",
    "        'Sitting Up (action)',\n",
    "        'Standing up (action)'\n",
    "        ]\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_transition_train = np.nan_to_num(X_train.values)\n",
    "X_transition_validation = np.nan_to_num(X_test[:int(len(X_test)*0.5)].values)\n",
    "X_transition_test = np.nan_to_num(X_test[int(len(X_test)*0.5):].values)\n",
    "activities_labels_train = np.nan_to_num(train_data[activity_label_names].values)\n",
    "activities_labels_validation = np.nan_to_num(test_data[activity_label_names][:int(len(X_test)*0.5)].values)\n",
    "activities_labels_test = np.nan_to_num(test_data[activity_label_names][int(len(X_test)*0.5):].values)\n",
    "\n",
    "X_activities_train = np.nan_to_num(X_train.values)\n",
    "X_activities_validation = np.nan_to_num(X_test[:int(len(X_test)*0.5)].values)\n",
    "X_activities_test = np.nan_to_num(X_test[int(len(X_test)*0.5):].values)\n",
    "transition_labels_train = np.nan_to_num(train_data[transition_label_names].values)\n",
    "transition_labels_validation = np.nan_to_num(test_data[transition_label_names][:int(len(X_test)*0.5)].values)\n",
    "transition_labels_test = np.nan_to_num(test_data[transition_label_names][int(len(X_test)*0.5):].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_activities_train = np.hstack((activities_labels_train, np.where(np.sum(activities_labels_train, axis=1) == 0, 1, 0).reshape(-1, 1)))\n",
    "Y_activities_validation = np.hstack((activities_labels_validation, np.where(np.sum(activities_labels_validation, axis=1) == 0, 1, 0).reshape(-1, 1)))\n",
    "Y_activities_test = np.hstack((activities_labels_test, np.where(np.sum(activities_labels_test, axis=1) == 0, 1, 0).reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_transition_train = np.hstack((transition_labels_train, np.where(np.sum(transition_labels_train, axis=1) == 0, 1, 0).reshape(-1, 1)))\n",
    "Y_transition_validation = np.hstack((transition_labels_validation, np.where(np.sum(transition_labels_validation, axis=1) == 0, 1, 0).reshape(-1, 1)))\n",
    "Y_transition_test = np.hstack((transition_labels_test, np.where(np.sum(transition_labels_test, axis=1) == 0, 1, 0).reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_label_names = np.array(transition_label_names + ['Unknown'])\n",
    "activity_label_names = np.array(activity_label_names + ['Unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, labels):\n",
    "    Y_onehot=[]\n",
    "    for l in y:\n",
    "        empty_label=np.zeros(len(labels))\n",
    "        empty_label[labels.index(l)]=1.\n",
    "        Y_onehot.append(empty_label)\n",
    "    return(np.vstack(Y_onehot))\n",
    "\n",
    "\n",
    "def get_metrics(target, output):\n",
    "        \n",
    "        pred = np.round(output)\n",
    "        \n",
    "        tp = np.sum(((pred + target) == 2).astype(float), axis=0)\n",
    "        fp = np.sum(((pred - target) == 1).astype(float), axis=0)\n",
    "        fn = np.sum(((pred - target) == -1).astype(float), axis=0)\n",
    "        tn = np.sum(((pred + target) == 0).astype(float), axis=0)\n",
    "\n",
    "        acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "        try:\n",
    "            prec = tp / (tp + fp)\n",
    "        except ZeroDivisionError:\n",
    "            prec = 0.0\n",
    "        try:\n",
    "            rec = tp / (tp + fn)\n",
    "        except ZeroDivisionError:\n",
    "            rec = 0.0\n",
    "        try:\n",
    "            specificity = tn / (tn + fp)\n",
    "        except ZeroDivisionError:\n",
    "            specificity = 0.0\n",
    "\n",
    "\n",
    "        try:\n",
    "            f1=2.*((prec*rec)/(prec+rec))\n",
    "        except ZeroDivisionError:\n",
    "            f1 = 0.0\n",
    "        \n",
    "        acc[acc != acc] = 0.\n",
    "        prec[prec != prec] = 0.\n",
    "        rec[rec != rec] = 0.\n",
    "        specificity[specificity != specificity] = 0.\n",
    "        f1[f1 != f1] = 0.\n",
    "        \n",
    "        balanced_accuracy = (rec + specificity) / 2.\n",
    "        \n",
    "        err_rate = np.subtract(1., acc)\n",
    "        f1_micro, f1_macro, f1_weight, log_ls, roc = [], [], [], [], []\n",
    "        for idx in range(target.shape[1]):\n",
    "            y_test=target[:,idx]\n",
    "            y_pred=pred[:,idx]\n",
    "            \n",
    "            f1_micro.append(f1_score(y_test, y_pred, average= 'micro'))\n",
    "            f1_macro.append(f1_score(y_test, y_pred, average= 'macro'))\n",
    "            f1_weight.append(f1_score(y_test, y_pred, average= 'weighted'))\n",
    "            log_ls.append(log_loss(y_test, y_pred, labels=[0., 1.]))\n",
    "            try:\n",
    "                roc.append(roc_auc_score(y_test, output[:, idx]))\n",
    "            except ValueError:\n",
    "                roc.append(np.nan)\n",
    "            \n",
    "        return (balanced_accuracy, acc, err_rate, prec, rec, specificity, f1, tp, fp, fn, tn, np.array(f1_micro), np.array(f1_macro), np.array(f1_weight), np.array(log_ls), np.array(roc))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_GRU(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Custom_GRU, self).__init__()\n",
    "        self.input_size = config[\"input_dim\"]\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.num_layers = config[\"num_layers\"] \n",
    "        self.output_size = config[\"output_dim\"]\n",
    "        self.learning_rate = config[\"learning_rate\"]\n",
    "        self.num_epochs = config[\"num_epochs\"]\n",
    "        self.num_directions = config[\"num_directions\"]\n",
    "                \n",
    "        if self.num_directions == 1:\n",
    "            bidirectional = False\n",
    "        elif self.num_directions == 2:\n",
    "            bidirectional = True\n",
    "        else:\n",
    "            print(\"Invalid value for number of directions\")\n",
    "            \n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=self.input_size, num_layers= self.num_layers, hidden_size=self.hidden_size,\n",
    "                          batch_first=True, bidirectional=bidirectional, dropout=0.1)\n",
    "        self.linear = nn.Linear(self.hidden_size*self.num_directions, self.output_size)\n",
    "        self.act = nn.Softmax()\n",
    "        #self.act = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        pred, hidden = self.rnn(x, None)\n",
    "        pred = self.act(self.linear(pred)).view(pred.data.shape[0], self.output_size)\n",
    "        #pred = nn.Sigmoid(self.linear(pred)).view(pred.data.shape[0], 12)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gru(config, train_inp, train_out, test_inp, test_out):\n",
    "    r= Custom_GRU(config).to(device)\n",
    "    predictions = []\n",
    "    optimizer = torch.optim.Adam(r.parameters(), lr=config[\"learning_rate\"])\n",
    "    #loss_func = nn.L1Loss()\n",
    "    loss_func = F.binary_cross_entropy\n",
    "\n",
    "    for t in range(config[\"num_epochs\"]):\n",
    "        hidden = None\n",
    "        inp = Variable(torch.from_numpy(train_inp.reshape((train_inp.shape[0], -1, config[\"input_dim\"]))).type(dtype), requires_grad=True)\n",
    "        out = Variable(torch.from_numpy(train_out.reshape((train_inp.shape[0], config[\"output_dim\"]))).type(dtype))\n",
    "    \n",
    "        pred = r(inp)\n",
    "        optimizer.zero_grad()\n",
    "        predictions.append(pred.data.cpu().numpy())\n",
    "        loss = loss_func(pred, out)\n",
    "        #print(loss)\n",
    "        if t%100==0:\n",
    "            print(t, loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    t_inp = Variable(torch.from_numpy(test_inp.reshape((test_inp.shape[0], -1, config[\"input_dim\"]))).type(dtype), requires_grad=True)\n",
    "    pred_t = r(t_inp)\n",
    "    pred_one_hot = pred_t.data.cpu().numpy()\n",
    "    results_metrics = get_metrics(test_out, pred_one_hot)\n",
    "    results_conf_mat = confusion_matrix(np.argmax(test_out, axis=1), np.argmax(pred_one_hot, axis=1))\n",
    "    metric_names = np.array([\"CV\", \"Balanced Accuracy\", \"Accuracy\", \"Error Rate\",\"Precision\",\"Recall\",\"Specificity\", \"F1\", \"TP\",\"FP\",\"FN\",\"TN\", \"Micro F1\",\"Macro F1\",\"Weighted F1\",\"Log-Loss\",\"ROC AUC\"])\n",
    "    results = np.hstack((metric_names.reshape(-1, 1), np.vstack((activity_label_names, np.vstack(results_metrics)))))\n",
    "    \n",
    "    filename=\"Activity_subset_classification_results_WASH_BiGRU_2_layers_512_hidden_1_directions\"\n",
    "    \n",
    "    with open(\"{}.csv\".format(filename), 'a') as f:\n",
    "        pd.DataFrame(results).to_csv(f, header=False)\n",
    "    with open(\"{}_conf_matrix.csv\".format(filename), 'a') as f:\n",
    "        conf_mat_labels = activity_label_names[np.unique(np.vstack((np.argmax(test_out, axis=1),np.argmax(pred_one_hot, axis=1))))]\n",
    "        #conf_mat_labels = activity_label_names\n",
    "        print(conf_mat_labels.reshape(-1, 1).shape, results_conf_mat.shape)\n",
    "        pd.DataFrame(np.hstack((conf_mat_labels.reshape(-1, 1), results_conf_mat))).to_csv(f, header=False)\n",
    "        \n",
    "    plt.subplots(figsize=(20,15))\n",
    "    s=sns.heatmap(results_conf_mat.astype(int), annot=True, annot_kws={\"size\": 20}, cmap=\"YlGnBu\", fmt='d', xticklabels=conf_mat_labels, yticklabels=conf_mat_labels)\n",
    "    title=\"Activity Learning\"\n",
    "    s.set_title(title)\n",
    "    \n",
    "    filename_modifier = 0\n",
    "    while(os.path.exists(filename+\"_\"+str(filename_modifier)+\".png\")):\n",
    "        filename_modifier+=1\n",
    "    fig_fname=filename+\"_\"+str(filename_modifier)+\".png\"\n",
    "    s.get_figure().savefig(fig_fname, dpi=400)\n",
    "    return pred_one_hot, test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config[\"input_dim\"] = 200\n",
    "config[\"hidden_size\"] = 512\n",
    "config[\"num_layers\"] = 1\n",
    "config[\"output_dim\"] = 12\n",
    "config[\"num_epochs\"] = 2000\n",
    "config[\"learning_rate\"] = 1e-3\n",
    "config[\"num_directions\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 4.94 GiB (GPU 0; 31.75 GiB total capacity; 1.82 GiB already allocated; 1.90 GiB free; 497.43 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0cab42eedbef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_act_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_act_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_activities_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_activities_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_act_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_act_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_act_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_act_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-4aeda38ea0cf>\u001b[0m in \u001b[0;36mtrain_gru\u001b[0;34m(config, train_inp, train_out, test_inp, test_out)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_inp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_dim\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-db58832ab82f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#self.act = nn.Tanh()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#pred = nn.Sigmoid(self.linear(pred)).view(pred.data.shape[0], 12)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/python3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.94 GiB (GPU 0; 31.75 GiB total capacity; 1.82 GiB already allocated; 1.90 GiB free; 497.43 MiB cached)"
     ]
    }
   ],
   "source": [
    "train_trans_inp, train_trans_out = X_transition_train, Y_transition_train\n",
    "val_trans_inp, val_trans_out = X_transition_validation, Y_transition_validation\n",
    "test_trans_inp, test_trans_out = X_transition_test, Y_transition_test\n",
    "\n",
    "train_act_inp, train_act_out = X_activities_train, Y_activities_train\n",
    "val_act_inp, val_act_out = X_activities_validation, Y_activities_validation\n",
    "test_act_inp, test_act_out = X_activities_test, Y_activities_test\n",
    "\n",
    "y_hat, y = train_gru(config, train_act_inp, train_act_out, val_act_inp, val_act_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5230356e-05, 2.5303743e-05, 2.5312966e-05, ..., 2.5331790e-05,\n",
       "        2.5307761e-05, 2.5371353e-05],\n",
       "       [2.5305062e-05, 2.5341671e-05, 2.5292004e-05, ..., 2.5375006e-05,\n",
       "        2.5361654e-05, 2.5301839e-05],\n",
       "       [2.5313790e-05, 2.5336329e-05, 2.5291080e-05, ..., 2.5285297e-05,\n",
       "        2.5301861e-05, 2.5299016e-05],\n",
       "       ...,\n",
       "       [2.5298656e-05, 2.5291904e-05, 2.5308120e-05, ..., 2.5346581e-05,\n",
       "        2.5363939e-05, 2.5279576e-05],\n",
       "       [2.5320023e-05, 2.5360794e-05, 2.5254885e-05, ..., 2.5308507e-05,\n",
       "        2.5336294e-05, 2.5317406e-05],\n",
       "       [2.5342815e-05, 2.5314446e-05, 2.5335150e-05, ..., 2.5278207e-05,\n",
       "        2.5306337e-05, 2.5325980e-05]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv_idx, cv_fold in enumerate(rand_uid):\n",
    "    train_ids, val_ids, test_ids = cv_fold[:int(0.6*len(cv_fold))], cv_fold[int(0.6*len(cv_fold)):int(0.8*len(cv_fold)):], cv_fold[int(0.8*len(cv_fold)):]\n",
    "\n",
    "    train_idx = np.isin(user_ids, train_ids)\n",
    "    val_idx = np.isin(user_ids, val_ids)\n",
    "    test_idx = np.isin(user_ids, test_ids)\n",
    "    \n",
    "    X_transition_train=X[train_idx]\n",
    "    X_transition_validation=X[val_idx]\n",
    "    X_transition_test=X[test_idx]\n",
    "    Y_transition_train=np.where(Y[train_idx] > 6, Y[train_idx], 0)\n",
    "    Y_transition_validation=np.where(Y[val_idx] > 6, Y[val_idx], 0)\n",
    "    Y_transition_test=np.where(Y[test_idx] > 6, Y[test_idx], 0)\n",
    "\n",
    "    train_inp, train_out = X_transition_train, one_hot(Y_transition_train, [0,7,8,9,10,11,12])\n",
    "    val_inp, val_out = X_transition_validation, one_hot(Y_transition_validation, [0,7,8,9,10,11,12])\n",
    "    test_inp, test_out = X_transition_test, one_hot(Y_transition_test, [0,7,8,9,10,11,12])\n",
    "\n",
    "    train_gru(config, train_inp, train_out, val_inp, val_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_GRU(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Custom_GRU, self).__init__()\n",
    "        self.input_size = config[\"input_dim\"]\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.num_layers = config[\"num_layers\"] \n",
    "        self.output_size = config[\"output_dim\"]\n",
    "        self.learning_rate = config[\"learning_rate\"]\n",
    "        self.num_epochs = config[\"num_epochs\"]\n",
    "        self.num_directions = config[\"num_directions\"]\n",
    "                \n",
    "        if config[\"num_directions\"] == 1:\n",
    "            bidirectional = False\n",
    "        elif config[\"num_directions\"] == 2:\n",
    "            bidirectional = True\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=self.input_size, num_layers= self.num_layers, hidden_size=self.hidden_size, \n",
    "                          batch_first=True, bidirectional=bidirectional, dropout=0.1).cuda()\n",
    "        self.linear = nn.Linear(self.hidden_size*self.num_directions, self.output_size)\n",
    "        self.act = nn.Softmax()\n",
    "        #self.act = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        pred, hidden = self.rnn(x, None)\n",
    "        pred = self.act(self.linear(pred)).view(pred.data.shape[0], self.output_size).cuda()\n",
    "        #pred = nn.Sigmoid(self.linear(pred)).view(pred.data.shape[0], 12)\n",
    "        return pred\n",
    "\n",
    "    def train_gru(self, train_inp, train_out, test_inp, test_out):\n",
    "        predictions = []\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        #loss_func = nn.L1Loss()\n",
    "        loss_func = F.binary_cross_entropy\n",
    "        train_loss = [] \n",
    "        for t in range(self.num_epochs):\n",
    "            hidden = None\n",
    "            inp = Variable(torch.from_numpy(train_inp.reshape((train_inp.shape[0], -1, self.input_size))).type(dtype), requires_grad=True)\n",
    "            out = Variable(torch.from_numpy(train_out.reshape((train_inp.shape[0], self.output_size))).type(dtype))\n",
    "        \n",
    "            pred = self.forward(inp)\n",
    "            optimizer.zero_grad()\n",
    "            predictions.append(pred.data.cpu().numpy())\n",
    "            loss = loss_func(pred, out)\n",
    "            train_loss.append(loss)\n",
    "            if t%100==0:\n",
    "                print(t, loss.data[0])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        t_inp = Variable(torch.Tensor(test_inp.reshape((test_inp.shape[0], -1, self.input_size))).type(dtype), requires_grad=True)\n",
    "        t_out = Variable(torch.Tensor(test_out.reshape((test_out.shape[0], self.output_size))).type(dtype))\n",
    "        pred_t = self.forward(t_inp)\n",
    "        test_loss = loss_func(pred_t, t_out)\n",
    "        pred_numpy = pred_t.data.cpu().numpy()\n",
    "        transition_act=np.where(np.argmax(pred_numpy, axis=1)==6, True, False)\n",
    "        #print(transition_act)\n",
    "        groups = [(list(v), g) for g,v in itertools.groupby(transition_act)]\n",
    "        processed=0\n",
    "        transition_y_hat=[]\n",
    "        #print(groups)\n",
    "        for group in groups:\n",
    "            cont=group[0]\n",
    "            g=group[1]\n",
    "            trans_pred=0\n",
    "            if g:\n",
    "                if(len(cont)>0):\n",
    "                    prev_act=np.argmax(pred_numpy[processed-1])+1\n",
    "                    next_act=np.argmax(pred_numpy[processed+len(cont)])+1\n",
    "                    if(prev_act==5 and next_act==4):\n",
    "                        trans_pred=7\n",
    "                    elif(prev_act==5 and next_act==6):\n",
    "                        trans_pred=11\n",
    "                    elif(prev_act==4 and next_act==5):\n",
    "                        trans_pred=8\n",
    "                    elif(prev_act==4 and next_act==6):\n",
    "                        trans_pred=9\n",
    "                    elif(prev_act==6 and next_act==4):\n",
    "                        trans_pred=10\n",
    "                    elif(prev_act==6 and next_act==5):\n",
    "                        #print(\"class 12 should be predicted\")\n",
    "                        trans_pred=12\n",
    "                    elif(prev_act==6 and next_act==1):\n",
    "                        trans_pred=12\n",
    "                    else:\n",
    "                        print(\"Unexpected Combination. Prev{}. Next{}\".format(prev_act, next_act))\n",
    "                    processed+=len(cont)\n",
    "                else:\n",
    "                    processed+=len(cont)\n",
    "            else:\n",
    "                processed+=len(cont)\n",
    "            transition_y_hat.append(np.ones_like(cont)*trans_pred)\n",
    "        transition_y_hat = np.hstack(transition_y_hat)\n",
    "        \n",
    "        pred_one_hot = one_hot(transition_y_hat, [0, 7, 8, 9, 10, 11, 12])\n",
    "        \n",
    "        results_metrics = get_metrics(test_out, pred_one_hot)\n",
    "        results_conf_mat = confusion_matrix(np.argmax(test_out, axis=1)+1, np.argmax(pred_one_hot, axis=1)+1)\n",
    "        metric_names = np.array([\"CV\", \"Balanced Accuracy\", \"Accuracy\", \"Error Rate\", \"Precision\",\"Recall\",\"Specificity\", \"F1\", \"TP\",\"FP\",\"FN\",\"TN\", \"Micro F1\",\"Macro F1\",\"Weighted F1\",\"Log-Loss\",\"ROC AUC\"])\n",
    "        results = np.hstack((metric_names.reshape(-1, 1), np.vstack((transition_label_names, np.vstack(results_metrics)))))\n",
    "        \n",
    "        filename= config[\"result_filename\"]\n",
    "        with open(\"{}.csv\".format(filename), 'a') as f:\n",
    "            pd.DataFrame(results).to_csv(f, header=False)\n",
    "        with open(\"{}_conf_matrix.csv\".format(filename), 'a') as f:    \n",
    "            pd.DataFrame(np.hstack((transition_label_names.reshape(-1, 1), results_conf_mat))).to_csv(f, header=False)\n",
    "        plt.subplots(figsize=(20,15))\n",
    "        sns.set(font_scale = 1.8)\n",
    "        s=sns.heatmap(results_conf_mat.astype(int), annot=True, annot_kws={\"size\": 20}, cmap=\"YlGnBu\", fmt='d', xticklabels=transition_label_names, yticklabels=transition_label_names)\n",
    "        title=\"Transition Learning\"\n",
    "        s.set_title(title)\n",
    "        \n",
    "        filename_modifier = 0\n",
    "        while(os.path.exists(filename+\"_\"+str(filename_modifier)+\".png\")):\n",
    "            filename_modifier+=1\n",
    "        fig_fname=filename+\"_\"+str(filename_modifier)+\".png\"\n",
    "        s.get_figure().savefig(fig_fname, dpi=400)\n",
    "        \n",
    "        with open(filename+\"_\"+str(filename_modifier)+\"_train_loss.csv\", 'wb') as train_loss_file:\n",
    "            wr = csv.writer(train_loss_file, quoting=csv.QUOTE_ALL)\n",
    "            wr.writerow(train_loss)\n",
    "        final_loss = test_loss.detach().cpu().numpy().item()\n",
    "        del inp\n",
    "        del self.rnn\n",
    "        del out\n",
    "        del t_inp\n",
    "        del t_out\n",
    "        del test_loss\n",
    "        del pred\n",
    "        del pred_t\n",
    "        del train_loss\n",
    "        torch.cuda.empty_cache()\n",
    "        plt.close()\n",
    "        return final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes=[256, 512, 1024]\n",
    "learning_rates=[1e-3]\n",
    "epochs=[1000]\n",
    "directions = [2]\n",
    "layers=[1]\n",
    "    \n",
    "hyperparameters = [hidden_layer_sizes, directions, layers, epochs, learning_rates]\n",
    "all_parameter_combinations=list(itertools.product(*hyperparameters))\n",
    "costs=[]\n",
    "for parameter_combo in all_parameter_combinations:\n",
    "    config = {}\n",
    "    config[\"input_dim\"] = 561\n",
    "    config[\"hidden_size\"] = parameter_combo[0] \n",
    "    config[\"num_directions\"] = parameter_combo[1]\n",
    "    config[\"num_layers\"] = parameter_combo[2]\n",
    "    config[\"output_dim\"] = 7\n",
    "    config[\"num_epochs\"] = parameter_combo[3]\n",
    "    config[\"learning_rate\"] = parameter_combo[4]\n",
    "    config[\"result_filename\"] = \"/home/kchandrasekaran/wash/activity_transitions/WASH/results/Inverse_Transition_classification_results_BiGRU_{}_directions_{}_layers_{}_lr_{}_units_{}_epochs\".format(config[\"num_directions\"], config[\"num_layers\"], config[\"learning_rate\"], config[\"hidden_size\"], config[\"num_epochs\"])\n",
    "    for cv_idx, cv_fold in enumerate(rand_uid):\n",
    "        train_ids, val_ids, test_ids = cv_fold[:int(0.6*len(cv_fold))], cv_fold[int(0.6*len(cv_fold)):int(0.8*len(cv_fold)):], cv_fold[int(0.8*len(cv_fold)):]\n",
    "        train_idx = np.isin(user_ids, train_ids)\n",
    "        val_idx = np.isin(user_ids, val_ids)\n",
    "        test_idx = np.isin(user_ids, test_ids)\n",
    "        \n",
    "        X_activity_train=X[train_idx]\n",
    "        X_activity_validation=X[val_idx]\n",
    "        X_activity_test=X[test_idx]\n",
    "        Y_activity_train=np.where(Y[train_idx] <= 6, Y[train_idx], 0)\n",
    "        Y_activity_validation=np.where(Y[val_idx] <= 6, Y[val_idx], 0)\n",
    "        Y_activity_test=np.where(Y[test_idx] <= 6, Y[test_idx], 0)\n",
    "        \n",
    "        X_transition_train=X[train_idx]\n",
    "        X_transition_validation=X[val_idx]\n",
    "        X_transition_test=X[test_idx]\n",
    "        Y_transition_train=np.where(Y[train_idx] > 6, Y[train_idx], 0)\n",
    "        Y_transition_validation=np.where(Y[val_idx] > 6, Y[val_idx], 0)\n",
    "        Y_transition_test=np.where(Y[test_idx] > 6, Y[test_idx], 0)\n",
    "        \n",
    "        train_act_inp, train_act_out = X_activity_train, one_hot(Y_activity_train, [1, 2, 3, 4, 5, 6, 0])\n",
    "        val_act_inp, val_act_out = X_activity_validation, one_hot(Y_activity_validation, [1, 2, 3, 4, 5, 6, 0])\n",
    "        test_act_inp, test_act_out = X_activity_test, one_hot(Y_activity_test, [1, 2, 3, 4, 5, 6, 0])\n",
    "            \n",
    "        train_trans_inp, train_trans_out = X_transition_train, one_hot(Y_transition_train, [0,7,8,9,10,11,12])\n",
    "        val_trans_inp, val_trans_out = X_transition_validation, one_hot(Y_transition_validation, [0,7,8,9,10,11,12])\n",
    "        test_trans_inp, test_trans_out = X_transition_test, one_hot(Y_transition_test, [0,7,8,9,10,11,12])\n",
    "        start_time = time.time()\n",
    "        model = Custom_GRU(config).to(device)\n",
    "        loss = model.train_gru(train_act_inp, train_act_out, val_act_inp, val_trans_out)\n",
    "        costs.append(loss)\n",
    "        config[\"CV_index\"] = cv_idx\n",
    "        config[\"test_loss\"] = loss\n",
    "        config[\"time_elapsed\"] = time.time()-start_time\n",
    "        with open(\"GRU_Inverse_GridSearch_results.csv\", 'a') as f:    \n",
    "            #print(config)\n",
    "            pd.DataFrame(config, index=[0]).to_csv(f, header=False)\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    best_params=all_parameter_combinations[np.argmin(costs)]\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
